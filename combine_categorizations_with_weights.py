# combine_categorizations_with_weights.py
# This file calculates the 3-digit NAICS industry "complement"
# and "substitute" values using: (1) the results of the
# categorization process performed by categorize_input_pairs.py
# (which itself uses the input/output quantity change data
# generated by import_io.py); and (2) the supplier-customer
# weights calculated by import_io.py.


# ***
# Load packages
# ***
import pandas as pd
import networkx as nx


# ***
# Load data and perform other initialization
# ***

# Specify the focus commodity for which to calculate
# complement and substitute values; categorization
# results will need to have been generated for this
# commodity and saved in /results_data/
focus_commodity = "324"  # petroleum and coal products

# Specify the year ranges within the categorization
# results to process
list_year_ranges = ["1964:2016"]  # this was the year range used to generate the industry 324 categorizations

# Specify the years of supplier-customer weight
# values to use from commodity_buyers.csv and
# industry_suppliers.csv; each range within this list
# should correspond to an element in list_year_ranges
list_weight_years = [range(2015, 2016)]  # calculate the values for the year 2015

# Set the cutoff level when determining the number of simple
# paths; only paths of this length or shorter are included
cutoff_level = 2

# Specify the values that represent complements and
# substitutes in the categorization results data
complements_value = 'C'
substitutes_value = 'S'

# Import the fraction of each commodity's total intermediate
# output purchased by each industry (calculated by the
# file import_io_data.py)
data_io_buyers = pd.read_csv("./processed_data/commodity_buyers.csv")

# Import the fraction of each industry's total intermediate
# input use supplied by each commodity (calculated by the
# file import_io_data.py)
data_io_suppliers = pd.read_csv("./processed_data/industry_suppliers.csv")

# Load the industry text descriptions
industry_descriptions = pd.read_csv("./processed_data/industry_descriptions.csv")

# Create a data frame to hold the final results
results = pd.DataFrame(columns=['year', 'industry', 'type', 'direction', 'value'])

# Create empty lists to hold the values as they
# are being calculated
list_year = []
list_ind = []
list_type = []
list_direction = []
list_val = []


# ***
# Calculate the complements and substitutes values
# ***

# Loop through each of the year ranges specified above
for list_index in range(0, len(list_year_ranges)):

    # Extract the current year range to process
    curr_year_range = list_year_ranges[list_index]

    # Extract the associated weight years to process
    curr_weight_years = list_weight_years[list_index]

    # Print a diagnostic message
    print("\nProcessing year range ", curr_year_range, ".\n", sep="")

    # Import the categorization results generated by
    # the process in categorize_input_pairs.py; each
    # row represents an industry, and the columns are how
    # the industry substitutes each commodity with the
    # focus commodity (e.g., petroleum products); each
    # industry may have multiple rows, which are the
    # results when using different sets of years to
    # train the model
    data = pd.read_csv("./results_data/categorization_results_python_focus" + focus_commodity + ".csv")

    # Replace any nan values with zeros
    data = data.fillna(0)

    # Extract the results for the specified year group
    data = data.loc[data.loc[:, "year"] == curr_year_range, :]

    # Convert the substitution results so that values
    # greater than a positive threshold are assigned a
    # certain value, and values less than a negative
    # threshold are assigned another value; this "thins
    # out" the network for processing below
    # data_reduce = data.copy()

    # Use the categorization results to create an adjacency matrix
    # in three steps: (1) create a list of industry names using the
    # values in the industry column; (2) create a copy of the
    # results data frame and make the industry column the index;
    # and (3) keep only the columns in the copy that have the same
    # names as the industry names, resulting in a square matrix
    ind_names = data.loc[:, "industry"]
    adj_matrix = data.copy()
    adj_matrix.set_index('industry', inplace=True)
    adj_matrix = adj_matrix[ind_names]

    # Transpose the adjacency matrix; this makes it so that
    # links point from suppliers to their customers
    adj_matrix = adj_matrix.transpose()

    # Extract the names of the columns; these represent the
    # list of commodities
    commodity_list = adj_matrix.columns

    # Specify which industries to create values for (setting industry_list
    # to commodity_list will create values for all industries)
    industry_list = commodity_list

    # Create two new adjacency matrices, one of which will
    # retain the "complement" links and one of which will
    # retain the "substitute" links (where the codes
    # indicating each of these link types are given above)
    adj_matrix_comp = adj_matrix.copy()
    adj_matrix_subs = adj_matrix.copy()

    # Loop through all columns in the original adjacency matrix
    for commodity in range(0, adj_matrix.shape[1]):

        # Extract the column name
        col_name = adj_matrix.columns[commodity]

        # Create the "complements" matrix by converting the complements
        # values to ones and the substitutes values to zeros; cast every
        # column as type int
        adj_matrix_comp.loc[adj_matrix_comp.loc[:, col_name] == complements_value, col_name] = 1
        adj_matrix_comp.loc[adj_matrix_comp.loc[:, col_name] == substitutes_value, col_name] = 0
        adj_matrix_comp.loc[:, col_name] = adj_matrix_comp.loc[:, col_name].astype(int)

        # Create the "substitutes" matrix by converting the substitutes
        # values to ones and the complements values to zeros; cast every
        # column as type int
        adj_matrix_subs.loc[adj_matrix_subs.loc[:, col_name] == complements_value, col_name] = 0
        adj_matrix_subs.loc[adj_matrix_subs.loc[:, col_name] == substitutes_value, col_name] = 1
        adj_matrix_subs.loc[:, col_name] = adj_matrix_subs.loc[:, col_name].astype(int)

    # Create NetworkX directed graphs using the complements and
    # substitutes adjacency matrices
    graph_comp = nx.from_pandas_adjacency(adj_matrix_comp, create_using=nx.DiGraph)
    graph_subs = nx.from_pandas_adjacency(adj_matrix_subs, create_using=nx.DiGraph)

    # Repeat the following process twice: once for the complements
    # network and once for the substitutes network
    for graph_type in ['complements', 'substitutes']:

        # Print a diagnostic message
        print("\n*** Calculating ", graph_type, " values ***\n", sep='')

        # Loop through the industries in the industries list
        for industry in industry_list:

            # For the current industry, look at both the downstream
            # and upstream paths
            for cov_direction in ['downstream', 'upstream']:

                # Loop through the years specified above
                for year in curr_weight_years:

                    # Initialize the total to be zero
                    total = 0

                    # For each industry in the outer loop, loop through all
                    # of the commodities in this inner loop
                    for commodity in commodity_list:

                        # For the "downstream" iteration, find all simple
                        # downstream paths from the current industry to the
                        # target commodity, using either the complements or
                        # substitutes network; for the "upstream" iteration,
                        # find all simple downstream paths from the target
                        # commodity to the current industry, using either the
                        # complements or substitutes network
                        if graph_type == 'complements':
                            if cov_direction == 'downstream':
                                paths = nx.all_simple_paths(graph_comp, industry, commodity, cutoff=cutoff_level)
                            else:
                                paths = nx.all_simple_paths(graph_comp, commodity, industry, cutoff=cutoff_level)
                        else:
                            if cov_direction == 'downstream':
                                paths = nx.all_simple_paths(graph_subs, industry, commodity, cutoff=cutoff_level)
                            else:
                                paths = nx.all_simple_paths(graph_subs, commodity, industry, cutoff=cutoff_level)

                        # For the "downstream" iteration, use the input-output
                        # values that represent the fraction of a commodity's
                        # intermediate output purchased by each industry; for
                        # the "upstream" iteration, use the input-output values
                        # that represent the fraction of an industry's total
                        # intermediate input use supplied by each commodity
                        if cov_direction == 'downstream':
                            # Extract the values for the current year
                            data_io = data_io_buyers.loc[data_io_buyers['year'] == year, :]
                        else:
                            # Extract the values for the current year
                            data_io = data_io_suppliers.loc[data_io_suppliers['year'] == year, :]

                        # Loop through each path in the path set
                        for path in paths:

                            # Initialize a variable to one; this will hold
                            # the product of the edge weights along this path
                            edges_product = 1

                            # Loop through each edge in the current path
                            for edge_num in range(0, len(path)-1):

                                # Extract the edge weight using the input-output data
                                edge_value = float(data_io.loc[
                                                  (data_io['commodity'] == path[edge_num]) &
                                                  (data_io['industry'] == path[edge_num+1]), 'value'])

                                # Multiply the current product by this edge weight (using the
                                # absolute value as there are a few negative entries for
                                # government industries in the original input-output data;
                                # the U.S. BEA notes that these negative values represent
                                # government sales)
                                edges_product *= abs(edge_value)

                            # Add the product for this path to the total
                            total += edges_product

                    # Append the year, industry, type, direction, and calculated
                    # total value to the appropriate lists
                    list_year.append(year)
                    list_ind.append(industry)
                    list_type.append(graph_type)
                    list_direction.append(cov_direction)
                    list_val.append(total)

                    # Print the downstream or upstream total across all paths for this industry
                    print("Total ",  cov_direction, " for ", industry, " in ", year, ": ", total, ".", sep="")


# ***
# Add the values to the data frame and save the results in .csv format
# ***

# Put the complements and substitutes values into the data frame
results['year'] = list_year
results['industry'] = list_ind
results['type'] = list_type
results['direction'] = list_direction
results['value'] = list_val

# Merge in the industry text descriptions
results = results.merge(industry_descriptions, on='industry', how='left')

# Reorder the columns
results = results[['year', 'industry', 'description', 'type', 'direction', 'value']]

# Write the results to a .csv file
results.to_csv('./results_data/complement_and_substitute_values_' + focus_commodity + '.csv',
               index=False)

# Create a wide version of the data where the complements and
# substitutes values each have their own column; add another
# column called "other" that contains the remainder after the
# complements and substitutes values are subtracted from one
results_wide = results \
    .pivot(index=['year', 'industry', 'description', 'direction'], columns="type", values="value") \
    .reset_index()
results_wide['other'] = 1 - results_wide['complements'] - results_wide['substitutes']

# Write the wide results to a .csv file
results_wide.to_csv('./results_data/complement_and_substitute_values_' + focus_commodity + '_wide.csv',
                    index=False)
